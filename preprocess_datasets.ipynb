{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import exists\n",
    "\n",
    "path = './Data/new_humor_datasets/'\n",
    "output_path = path + 'temp_run/'\n",
    "datasets = ['amazon', 'yelp_reviews', 'sarcasm_headlines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df_amazon = pd.read_csv(path + 'amazon/data.csv')\n",
    "df_yelp = pd.read_csv(path + 'yelp_reviews/data.csv')\n",
    "df_yelp_short = pd.read_csv(path + 'yelp_reviews/data_short.csv')\n",
    "df_headlines = pd.read_csv(path + 'sarcasm_headlines/data.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_train_test_val(df, path):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    train, test = train_test_split(df, test_size=0.3, shuffle=True, random_state=0)\n",
    "    test, val = train_test_split(test, test_size=0.5, shuffle=True, random_state=0)\n",
    "    test.to_csv(f'{path}/test.csv', index=False)\n",
    "    train.to_csv(f'{path}/train.csv', index=False)\n",
    "    val.to_csv(f'{path}/val.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def process_and_save_dataset(df_new, path):\n",
    "    df_new = df_new.sample(frac=1, random_state=0)\n",
    "    cols = ['id', 'bert_sentence', 't5_sentence', 'target', 'label']\n",
    "    df_new = df_new[cols]\n",
    "\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    df_new.to_csv(f'{path}/data.csv', index=False)\n",
    "\n",
    "    split_train_test_val(df_new, f'{path}/with_val')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Move amazon to temp_run dir"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "output_path_amzaon = output_path + 'amazon'\n",
    "process_and_save_dataset(df_amazon, output_path_amzaon)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Process Yelp Dataset & save"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_yelp_new = pd.DataFrame()\n",
    "df_yelp_new['bert_sentence'] = df_yelp['sentence']\n",
    "df_yelp_new['t5_sentence'] = df_yelp['sentence']\n",
    "df_yelp_new['label'] = df_yelp['label']\n",
    "df_yelp_new['target'] = df_yelp_new['label'].apply(lambda label: 'funny' if label == 1 else 'not funny')\n",
    "df_yelp_new = df_yelp_new[df_yelp_new['bert_sentence'].notna()]\n",
    "df_yelp_new = df_yelp_new[df_yelp_new['t5_sentence'].notna()]\n",
    "df_yelp_new['id'] = range(0, len(df_yelp_new))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "output_path_yelp = output_path + 'yelp'\n",
    "process_and_save_dataset(df_yelp_new, output_path_yelp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Process YelpShort Dataset (shorter sentences)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "df_yelp_short_new = pd.DataFrame()\n",
    "df_yelp_short_new['bert_sentence'] = df_yelp_short['sentence']\n",
    "df_yelp_short_new['t5_sentence'] = df_yelp_short['sentence']\n",
    "df_yelp_short_new['label'] = df_yelp_short['label']\n",
    "df_yelp_short_new['target'] = df_yelp_short_new['label'].apply(lambda label: 'funny' if label == 1 else 'not funny')\n",
    "df_yelp_short_new = df_yelp_short_new[df_yelp_short_new['bert_sentence'].notna()]\n",
    "df_yelp_short_new = df_yelp_short_new[df_yelp_short_new['t5_sentence'].notna()]\n",
    "df_yelp_short_new['id'] = range(0, len(df_yelp_short_new))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "output_path_yelp_short = output_path + 'yelp_short'\n",
    "process_and_save_dataset(df_yelp_short_new, output_path_yelp_short)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Process Sarcasm Headlines Dataset & Save"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "df_headlines_new = pd.DataFrame()\n",
    "df_headlines_new['bert_sentence'] = df_headlines['sentence']\n",
    "df_headlines_new['t5_sentence'] = df_headlines['sentence']\n",
    "df_headlines_new['label'] = df_headlines['label']\n",
    "df_headlines_new['target'] = df_headlines_new['label'].apply(lambda label: 'funny' if label == 1 else 'not funny')\n",
    "df_headlines_new = df_headlines_new[df_headlines_new['bert_sentence'].notna()]\n",
    "df_headlines_new = df_headlines_new[df_headlines_new['t5_sentence'].notna()]\n",
    "df_headlines_new['id'] = range(0, len(df_headlines_new))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "output_path_headlines = output_path + 'sarcasm_headlines'\n",
    "process_and_save_dataset(df_headlines_new, output_path_headlines)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Clean Reddit Dad Jokes (as much as possible)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "dadjokes_path = './Data/new_humor_datasets/reddit_dadjokes/'\n",
    "# load Reddit Dad Jokes dataset\n",
    "df_dadjokes = pd.read_csv(dadjokes_path + 'reddit_dadjokes.csv')\n",
    "\n",
    "# clean from duplicates and reposts\n",
    "df_dadjokes = df_dadjokes[df_dadjokes['joke'].apply(lambda joke: 'reposted' not in joke.lower())]\n",
    "df_dadjokes.drop_duplicates(inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# df_dadjokes['id'] = range(1, len(df_dadjokes) + 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### remove problematic samples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "indices_to_remove = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "indices_to_remove.append(df_dadjokes[df_dadjokes.joke == 'test test'].index[0])\n",
    "indices_to_remove.append(df_dadjokes[df_dadjokes['joke'].apply(lambda joke: 'Game Log Output Begins Here' in joke)].index[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "df_dadjokes.drop(indices_to_remove, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "df_dadjokes['id'] = range(1, len(df_dadjokes) + 1)\n",
    "df_dadjokes.to_csv(dadjokes_path + 'reddit_dadjokes_with_id.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}