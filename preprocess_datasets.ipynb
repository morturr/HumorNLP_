{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import exists\n",
    "\n",
    "path = './Data/new_humor_datasets/'\n",
    "balance_path = './Data/new_humor_datasets/balanced/'\n",
    "output_path = path + 'Datasets/'\n",
    "datasets = ['amazon', 'yelp_reviews', 'sarcasm_headlines', 'one_liners', 'reddit_dadjokes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './Data/new_humor_datasets/amazon/data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m df_amazon \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mamazon/data.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m df_yelp \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(path \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124myelp_reviews/data.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      3\u001B[0m df_headlines \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(path \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msarcasm_headlines/data.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\HumorNLP_\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[0;32m   1013\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m   1014\u001B[0m     dialect,\n\u001B[0;32m   1015\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1022\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[0;32m   1023\u001B[0m )\n\u001B[0;32m   1024\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m-> 1026\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\HumorNLP_\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    617\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m    619\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[1;32m--> 620\u001B[0m parser \u001B[38;5;241m=\u001B[39m TextFileReader(filepath_or_buffer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    622\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[0;32m    623\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[1;32m~\\PycharmProjects\\HumorNLP_\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m   1617\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m   1619\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1620\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\HumorNLP_\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1878\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[0;32m   1879\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1880\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1881\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1882\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1883\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1884\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1885\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1886\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1887\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1888\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1889\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1890\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1891\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[1;32m~\\PycharmProjects\\HumorNLP_\\venv\\lib\\site-packages\\pandas\\io\\common.py:873\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    868\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    869\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[0;32m    870\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[0;32m    871\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[0;32m    872\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[1;32m--> 873\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    874\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    875\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    876\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    877\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    878\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    879\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    880\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    881\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[0;32m    882\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: './Data/new_humor_datasets/amazon/data.csv'"
     ]
    }
   ],
   "source": [
    "df_amazon = pd.read_csv(path + 'amazon/data.csv')\n",
    "df_yelp = pd.read_csv(path + 'yelp_reviews/data.csv')\n",
    "df_headlines = pd.read_csv(path + 'sarcasm_headlines/data.csv')\n",
    "df_dad_jokes = pd.read_csv(path + 'reddit_dadjokes/data.csv')\n",
    "df_one_liners = pd.read_csv(path + 'one_liners/data.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: amazon, Size = 19094\n",
      "Dataset: yelp, Size = 19416\n",
      "Dataset: headlines, Size = 28617\n",
      "Dataset: dad_jokes, Size = 22048\n",
      "Dataset: one_liners, Size = 32000\n"
     ]
    }
   ],
   "source": [
    "dfs = {'amazon': df_amazon, 'yelp': df_yelp, 'headlines': df_headlines, 'dad_jokes': df_dad_jokes, 'one_liners': df_one_liners}\n",
    "for key, value in dfs.items():\n",
    "    print(f'Dataset: {key}, Size = {len(value)}')\n",
    "\n",
    "DATASET_SIZE = 19000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_train_test_val(df, path):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    train, test = train_test_split(df, test_size=0.3, shuffle=True, random_state=0)\n",
    "    test, val = train_test_split(test, test_size=0.5, shuffle=True, random_state=0)\n",
    "    test.to_csv(f'{path}/test.csv', index=False)\n",
    "    train.to_csv(f'{path}/train.csv', index=False)\n",
    "    val.to_csv(f'{path}/val.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def process_and_save_dataset(df_new, path):\n",
    "    df_new = df_new.sample(frac=1, random_state=0)\n",
    "    cols = ['id', 'bert_sentence', 't5_sentence', 'target', 'label']\n",
    "    df_new = df_new[cols]\n",
    "\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    df_new.to_csv(f'{path}/data.csv', index=False)\n",
    "\n",
    "    split_train_test_val(df_new, f'{path}/with_val')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Move amazon to temp_run dir"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "output_path_amzaon = output_path + 'amazon'\n",
    "process_and_save_dataset(df_amazon, output_path_amzaon)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Process Yelp Dataset & save"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_yelp_new = pd.DataFrame()\n",
    "df_yelp_new['bert_sentence'] = df_yelp['sentence']\n",
    "df_yelp_new['t5_sentence'] = df_yelp['sentence']\n",
    "df_yelp_new['label'] = df_yelp['label']\n",
    "df_yelp_new['target'] = df_yelp_new['label'].apply(lambda label: 'funny' if label == 1 else 'not funny')\n",
    "df_yelp_new = df_yelp_new[df_yelp_new['bert_sentence'].notna()]\n",
    "df_yelp_new = df_yelp_new[df_yelp_new['t5_sentence'].notna()]\n",
    "df_yelp_new['id'] = range(0, len(df_yelp_new))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "output_path_yelp = output_path + 'yelp'\n",
    "process_and_save_dataset(df_yelp_new, output_path_yelp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Process YelpShort Dataset (shorter sentences)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "df_yelp_short_new = pd.DataFrame()\n",
    "df_yelp_short_new['bert_sentence'] = df_yelp_short['sentence']\n",
    "df_yelp_short_new['t5_sentence'] = df_yelp_short['sentence']\n",
    "df_yelp_short_new['label'] = df_yelp_short['label']\n",
    "df_yelp_short_new['target'] = df_yelp_short_new['label'].apply(lambda label: 'funny' if label == 1 else 'not funny')\n",
    "df_yelp_short_new = df_yelp_short_new[df_yelp_short_new['bert_sentence'].notna()]\n",
    "df_yelp_short_new = df_yelp_short_new[df_yelp_short_new['t5_sentence'].notna()]\n",
    "df_yelp_short_new['id'] = range(0, len(df_yelp_short_new))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "output_path_yelp_short = output_path + 'yelp_short'\n",
    "process_and_save_dataset(df_yelp_short_new, output_path_yelp_short)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Process Sarcasm Headlines Dataset & Save"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "df_headlines_new = pd.DataFrame()\n",
    "df_headlines_new['bert_sentence'] = df_headlines['sentence']\n",
    "df_headlines_new['t5_sentence'] = df_headlines['sentence']\n",
    "df_headlines_new['label'] = df_headlines['label']\n",
    "df_headlines_new['target'] = df_headlines_new['label'].apply(lambda label: 'funny' if label == 1 else 'not funny')\n",
    "df_headlines_new = df_headlines_new[df_headlines_new['bert_sentence'].notna()]\n",
    "df_headlines_new = df_headlines_new[df_headlines_new['t5_sentence'].notna()]\n",
    "df_headlines_new['id'] = range(0, len(df_headlines_new))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "output_path_headlines = output_path + 'sarcasm_headlines'\n",
    "process_and_save_dataset(df_headlines_new, output_path_headlines)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Clean Reddit Dad Jokes (as much as possible)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "dadjokes_path = './Data/new_humor_datasets/reddit_dadjokes/'\n",
    "# load Reddit Dad Jokes dataset\n",
    "df_dadjokes = pd.read_csv(dadjokes_path + 'reddit_dadjokes.csv')\n",
    "\n",
    "# clean from duplicates and reposts\n",
    "df_dadjokes = df_dadjokes[df_dadjokes['joke'].apply(lambda joke: 'reposted' not in joke.lower())]\n",
    "df_dadjokes.drop_duplicates(inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# df_dadjokes['id'] = range(1, len(df_dadjokes) + 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### remove problematic samples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "indices_to_remove = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "indices_to_remove.append(df_dadjokes[df_dadjokes.joke == 'test test'].index[0])\n",
    "indices_to_remove.append(df_dadjokes[df_dadjokes['joke'].apply(lambda joke: 'Game Log Output Begins Here' in joke)].index[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "df_dadjokes.drop(indices_to_remove, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "df_dadjokes['id'] = range(1, len(df_dadjokes) + 1)\n",
    "df_dadjokes.to_csv(dadjokes_path + 'reddit_dadjokes_with_id.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Check balanced sets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df_amazon = pd.read_csv(balance_path + 'amazon/data.csv')\n",
    "df_yelp = pd.read_csv(balance_path + 'yelp_reviews/data.csv')\n",
    "df_headlines = pd.read_csv(balance_path + 'headlines/data.csv')\n",
    "df_dad_jokes = pd.read_csv(balance_path + 'dadjokes/data.csv')\n",
    "df_one_liners = pd.read_csv(balance_path + 'one_liners/data.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def print_df_labels_stat(df, df_name, sent_col_name):\n",
    "    print(f'stats for {df_name}:')\n",
    "    print(f'{df_name} len = {len(df)}')\n",
    "    df_label_0 = df[df.label == 0]\n",
    "    df_label_1 = df[df.label == 1]\n",
    "    print(f'% 0 labels = {\"%.2f\" %  (100 * (len(df_label_0) / len(df)))}')\n",
    "    print(f'% 1 labels = {\"%.2f\" %  (100 * (len(df_label_1) / len(df)))}')\n",
    "    print(f'avg sentence length label 0 = {\"%.2f\" %  np.mean(df_label_0[sent_col_name].apply(lambda s: len(s)))}')\n",
    "    print(f'avg sentence length label 1 = {\"%.2f\" %  np.mean(df_label_1[sent_col_name].apply(lambda s: len(s)))}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# setting same column text name to all\n",
    "df_amazon.drop('bert_sentence', axis=1, inplace=True)\n",
    "df_amazon.rename(columns={'t5_sentence': 'text'}, inplace=True)\n",
    "df_headlines.rename(columns={'sentence': 'text'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: amazon\n",
      "Size = 19000\n",
      "Label 0 % = 0.50\n",
      "Label 1 % = 0.50\n",
      "stats for amazon:\n",
      "amazon len = 19000\n",
      "% 0 labels = 50.00\n",
      "% 1 labels = 50.00\n",
      "avg sentence length label 0 = 141.13\n",
      "avg sentence length label 1 = 140.47\n",
      "---------\n",
      "Dataset: yelp_reviews\n",
      "Size = 19000\n",
      "Label 0 % = 0.50\n",
      "Label 1 % = 0.50\n",
      "stats for yelp_reviews:\n",
      "yelp_reviews len = 19000\n",
      "% 0 labels = 50.00\n",
      "% 1 labels = 50.00\n",
      "avg sentence length label 0 = 625.78\n",
      "avg sentence length label 1 = 628.60\n",
      "---------\n",
      "Dataset: headlines\n",
      "Size = 19000\n",
      "Label 0 % = 0.50\n",
      "Label 1 % = 0.50\n",
      "stats for headlines:\n",
      "headlines len = 19000\n",
      "% 0 labels = 50.00\n",
      "% 1 labels = 50.00\n",
      "avg sentence length label 0 = 59.58\n",
      "avg sentence length label 1 = 65.32\n",
      "---------\n",
      "Dataset: dadjokes\n",
      "Size = 19000\n",
      "Label 0 % = 0.50\n",
      "Label 1 % = 0.50\n",
      "stats for dadjokes:\n",
      "dadjokes len = 19000\n",
      "% 0 labels = 50.00\n",
      "% 1 labels = 50.00\n",
      "avg sentence length label 0 = 86.09\n",
      "avg sentence length label 1 = 86.11\n",
      "---------\n",
      "Dataset: one_liners\n",
      "Size = 19000\n",
      "Label 0 % = 0.50\n",
      "Label 1 % = 0.50\n",
      "stats for one_liners:\n",
      "one_liners len = 19000\n",
      "% 0 labels = 50.00\n",
      "% 1 labels = 50.00\n",
      "avg sentence length label 0 = 50.67\n",
      "avg sentence length label 1 = 68.65\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "dfs = {'amazon': df_amazon, 'yelp_reviews': df_yelp, 'headlines': df_headlines, 'dadjokes': df_dad_jokes, 'one_liners': df_one_liners}\n",
    "for key, value in dfs.items():\n",
    "    print(f'Dataset: {key}')\n",
    "    print(f'Size = {len(value)}')\n",
    "    print(f'Label 0 % = {\"%.2f\" % (len(value[value.label == 0]) / len(value))}')\n",
    "    print(f'Label 1 % = {\"%.2f\" % (len(value[value.label == 1]) / len(value))}')\n",
    "    print_df_labels_stat(value, key, 'text')\n",
    "    print('---------')\n",
    "    value.to_csv(f'{balance_path}{key}/data.csv', index=False)\n",
    "\n",
    "\n",
    "DATASET_SIZE = 19000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}