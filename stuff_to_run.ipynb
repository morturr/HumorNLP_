{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## create predictions file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "{(1, 2, 3, 5): 6, (2, 3, 3, 6): 8}"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = [3, 3]\n",
    "batch_sizes = [8]\n",
    "lrs = [5e-5, 1e-6, 1e-5]  # [5e-5, 1e-6]\n",
    "seeds = [42]\n",
    "\n",
    "results = {}\n",
    "results[1,2, 3, 5] = 6\n",
    "results[2, 3, 3, 6] = 8\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "results_file_path = 'Data/output/results/{model_name}_on_{dataset}_{date}'.format(\n",
    "    model_name='t5',\n",
    "    dataset='igg',\n",
    "    date='23_08_2023'\n",
    ")\n",
    "\n",
    "with open(results_file_path, 'a') as f:\n",
    "    for k, v in results.items():\n",
    "        f.write(f'ep: {k[0]}, bs: {k[1]}, lr: {k[2]}, seed: {k[3]}\\n')\n",
    "        f.write(f'accuracy = {v}\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# find smallest test size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test size of amazon is 8359\n",
      "test size of headlines is 5150\n",
      "test size of igg is 519\n",
      "test size of twss is 788\n"
     ]
    }
   ],
   "source": [
    "path = './Data/humor_datasets/{dataset}/with_val_fixed_train/test.csv'\n",
    "test_size = None\n",
    "datasets = ['amazon', 'headlines', 'igg', 'twss']\n",
    "for dataset in datasets:\n",
    "    df = pd.read_csv(path.format(dataset=dataset))\n",
    "    print(f'test size of {dataset} is {len(df)}')\n",
    "test_size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size of amazon is 2376\n",
      "label 1 count is 1188\n",
      "train size of headlines is 2376\n",
      "label 1 count is 1188\n",
      "train size of igg is 2376\n",
      "label 1 count is 1188\n",
      "train size of twss is 2376\n",
      "label 1 count is 1188\n"
     ]
    }
   ],
   "source": [
    "path = './Data/humor_datasets/{dataset}/with_val_fixed_train/train.csv'\n",
    "train_size = None\n",
    "datasets = ['amazon', 'headlines', 'igg', 'twss']\n",
    "for dataset in datasets:\n",
    "    df = pd.read_csv(path.format(dataset=dataset))\n",
    "    print(f'train size of {dataset} is {len(df)}')\n",
    "    print(f'label 1 count is {len(df[df.label==1])}')\n",
    "train_size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val size of amazon is 8359\n",
      "val size of headlines is 5150\n",
      "val size of igg is 519\n",
      "val size of twss is 788\n"
     ]
    }
   ],
   "source": [
    "path = './Data/humor_datasets/{dataset}/with_val_fixed_train/val.csv'\n",
    "val_size = None\n",
    "datasets = ['amazon', 'headlines', 'igg', 'twss']\n",
    "for dataset in datasets:\n",
    "    df = pd.read_csv(path.format(dataset=dataset))\n",
    "    print(f'val size of {dataset} is {len(df)}')\n",
    "val_size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# distribution of test labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for amazon:\n",
      "%label 1 = 50.77, %label 0 = 49.23\n",
      "for headlines:\n",
      "%label 1 = 48.86, %label 0 = 51.14\n",
      "for igg:\n",
      "%label 1 = 52.79, %label 0 = 47.21\n",
      "for twss:\n",
      "%label 1 = 47.84, %label 0 = 52.16\n"
     ]
    }
   ],
   "source": [
    "path = './Data/humor_datasets/{dataset}/with_val_fixed_train/test.csv'\n",
    "max_test_size = 3500\n",
    "datasets = ['amazon', 'headlines', 'igg', 'twss']\n",
    "for dataset in datasets:\n",
    "    df = pd.read_csv(path.format(dataset=dataset))\n",
    "    df = df.iloc[:min(len(df), max_test_size)]\n",
    "    df_1 = df[df.label == 1]\n",
    "    df_0 = df[df.label == 0]\n",
    "\n",
    "    # print(f'test size of {dataset} is {len(df)}')\n",
    "    print(f'for {dataset}:')\n",
    "    print(f'%label 1 = {\"%.2f\" % (100 * len(df_1) / len(df))}, %label 0 = {\"%.2f\" % (100 * len(df_0) / len(df))}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# distribution of paired val label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for amazon_headlines:\n",
      "val size = 1038\n",
      "%label 1 = 48.84, %label 0 = 51.16\n",
      "for amazon_igg:\n",
      "val size = 1038\n",
      "%label 1 = 48.55, %label 0 = 51.45\n",
      "for amazon_twss:\n",
      "val size = 1038\n",
      "%label 1 = 49.90, %label 0 = 50.10\n",
      "for headlines_igg:\n",
      "val size = 1038\n",
      "%label 1 = 47.50, %label 0 = 52.50\n",
      "for headlines_twss:\n",
      "val size = 1038\n",
      "%label 1 = 48.84, %label 0 = 51.16\n",
      "for igg_twss:\n",
      "val size = 1038\n",
      "%label 1 = 48.55, %label 0 = 51.45\n"
     ]
    }
   ],
   "source": [
    "path = './Data/humor_datasets/paired_datasets/{dataset}/with_val_fixed_train/val.csv'\n",
    "max_val_size = 3500\n",
    "datasets = [\"amazon_headlines\", \"amazon_igg\", \"amazon_twss\", \"headlines_igg\", \"headlines_twss\", \"igg_twss\"]\n",
    "for dataset in datasets:\n",
    "    df = pd.read_csv(path.format(dataset=dataset))\n",
    "    df = df.iloc[:min(len(df), max_val_size)]\n",
    "    df_1 = df[df.label == 1]\n",
    "    df_0 = df[df.label == 0]\n",
    "\n",
    "    print(f'for {dataset}:')\n",
    "    print(f'val size = {len(df)}')\n",
    "    print(f'%label 1 = {\"%.2f\" % (100 * len(df_1) / len(df))}, %label 0 = {\"%.2f\" % (100 * len(df_0) / len(df))}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# distribution of val labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './Data/humor_datasets/amazon_headlines/with_val_fixed_train/val.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_19700/1306269948.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mdatasets\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;34m\"amazon_headlines\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"amazon_igg\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"amazon_twss\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"headlines_igg\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"headlines_twss\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"igg_twss\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mdataset\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mdatasets\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m     \u001B[0mdf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m     \u001B[0mdf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0miloc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0mmin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmax_val_size\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m     \u001B[0mdf_1\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdf\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mdf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlabel\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    309\u001B[0m                     \u001B[0mstacklevel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mstacklevel\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    310\u001B[0m                 )\n\u001B[1;32m--> 311\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    312\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    313\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    584\u001B[0m     \u001B[0mkwds\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkwds_defaults\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    585\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 586\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    587\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    588\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    480\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    481\u001B[0m     \u001B[1;31m# Create the parser.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 482\u001B[1;33m     \u001B[0mparser\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    483\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    484\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m    809\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"has_index_names\"\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"has_index_names\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    810\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 811\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    812\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    813\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[1;34m(self, engine)\u001B[0m\n\u001B[0;32m   1038\u001B[0m             )\n\u001B[0;32m   1039\u001B[0m         \u001B[1;31m# error: Too many arguments for \"ParserBase\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1040\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mmapping\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# type: ignore[call-arg]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1041\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1042\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_failover_to_python\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, src, **kwds)\u001B[0m\n\u001B[0;32m     49\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     50\u001B[0m         \u001B[1;31m# open handles\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 51\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_open_handles\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     52\u001B[0m         \u001B[1;32massert\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhandles\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     53\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001B[0m in \u001B[0;36m_open_handles\u001B[1;34m(self, src, kwds)\u001B[0m\n\u001B[0;32m    220\u001B[0m         \u001B[0mLet\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mreaders\u001B[0m \u001B[0mopen\u001B[0m \u001B[0mIOHandles\u001B[0m \u001B[0mafter\u001B[0m \u001B[0mthey\u001B[0m \u001B[0mare\u001B[0m \u001B[0mdone\u001B[0m \u001B[1;32mwith\u001B[0m \u001B[0mtheir\u001B[0m \u001B[0mpotential\u001B[0m \u001B[0mraises\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    221\u001B[0m         \"\"\"\n\u001B[1;32m--> 222\u001B[1;33m         self.handles = get_handle(\n\u001B[0m\u001B[0;32m    223\u001B[0m             \u001B[0msrc\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    224\u001B[0m             \u001B[1;34m\"r\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001B[0m in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    700\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mioargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mencoding\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;34m\"b\"\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mioargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    701\u001B[0m             \u001B[1;31m# Encoding\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 702\u001B[1;33m             handle = open(\n\u001B[0m\u001B[0;32m    703\u001B[0m                 \u001B[0mhandle\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    704\u001B[0m                 \u001B[0mioargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: './Data/humor_datasets/amazon_headlines/with_val_fixed_train/val.csv'"
     ]
    }
   ],
   "source": [
    "path = './Data/humor_datasets/{dataset}/with_val_fixed_train/val.csv'\n",
    "max_val_size = 3500\n",
    "datasets = ['amazon', 'headlines', 'igg', 'twss']\n",
    "for dataset in datasets:\n",
    "    df = pd.read_csv(path.format(dataset=dataset))\n",
    "    df = df.iloc[:min(len(df), max_val_size)]\n",
    "    df_1 = df[df.label == 1]\n",
    "    df_0 = df[df.label == 0]\n",
    "\n",
    "    print(f'for {dataset}:')\n",
    "    print(f'%label 1 = {\"%.2f\" % (100 * len(df_1) / len(df))}, %label 0 = {\"%.2f\" % (100 * len(df_0) / len(df))}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# compute performance of the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def get_run_details(run_name):\n",
    "    run_data = run_name.split('_')\n",
    "    model = run_data[0]\n",
    "    dataset_name = run_data[2]\n",
    "    seed = run_data[3][run_data[3].index('=') + 1:]\n",
    "\n",
    "    # return model, dataset_name, float(seed)\n",
    "    return dataset_name, float(seed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance for ./Model/SavedModels/Bert-paired\\bert_on_amazon-headlines_seed=5\n",
      "accuracies = {'amazon': 0.8329, 'headlines': 0.5674, 'igg': 0.6301, 'twss': 0.2538}\n",
      "recall = {'amazon': 0.8362, 'headlines': 0.5988, 'igg': 0.3285, 'twss': 0.3581}\n",
      "precision = {'amazon': 0.8348, 'headlines': 0.5529, 'igg': 0.9184, 'twss': 0.2807}\n",
      "performance for ./Model/SavedModels/Bert-paired\\bert_on_amazon-igg_seed=5\n",
      "accuracies = {'amazon': 0.8346, 'headlines': 0.4957, 'igg': 0.8882, 'twss': 0.3566}\n",
      "recall = {'amazon': 0.8244, 'headlines': 0.9912, 'igg': 0.8905, 'twss': 0.7082}\n",
      "precision = {'amazon': 0.8458, 'headlines': 0.492, 'igg': 0.8971, 'twss': 0.4021}\n",
      "performance for ./Model/SavedModels/Bert-paired\\bert_on_amazon-twss_seed=18\n",
      "accuracies = {'amazon': 0.812, 'headlines': 0.5034, 'igg': 0.8651, 'twss': 0.9937}\n",
      "recall = {'amazon': 0.8351, 'headlines': 0.7544, 'igg': 0.8394, 'twss': 0.9947}\n",
      "precision = {'amazon': 0.8026, 'headlines': 0.4946, 'igg': 0.8984, 'twss': 0.9921}\n",
      "performance for ./Model/SavedModels/Bert-paired\\bert_on_headlines-igg_seed=42\n",
      "accuracies = {'amazon': 0.6951, 'headlines': 0.5811, 'igg': 0.8863, 'twss': 0.8553}\n",
      "recall = {'amazon': 0.816, 'headlines': 0.6509, 'igg': 0.8759, 'twss': 0.9894}\n",
      "precision = {'amazon': 0.6621, 'headlines': 0.5616, 'igg': 0.9057, 'twss': 0.7723}\n",
      "performance for ./Model/SavedModels/Bert-paired\\bert_on_headlines-twss_seed=27\n",
      "accuracies = {'amazon': 0.6794, 'headlines': 0.5723, 'igg': 0.869, 'twss': 0.9886}\n",
      "recall = {'amazon': 0.8368, 'headlines': 0.5924, 'igg': 0.865, 'twss': 0.992}\n",
      "precision = {'amazon': 0.6412, 'headlines': 0.5587, 'igg': 0.8843, 'twss': 0.9842}\n",
      "performance for ./Model/SavedModels/Bert-paired\\bert_on_igg-twss_seed=5\n",
      "accuracies = {'amazon': 0.5737, 'headlines': 0.5137, 'igg': 0.8613, 'twss': 0.981}\n",
      "recall = {'amazon': 0.9111, 'headlines': 0.8883, 'igg': 0.8613, 'twss': 0.992}\n",
      "precision = {'amazon': 0.5483, 'headlines': 0.5013, 'igg': 0.8741, 'twss': 0.9689}\n"
     ]
    }
   ],
   "source": [
    "from os.path import exists\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "import glob\n",
    "import os\n",
    "\n",
    "output_path = './Data/output/results/'\n",
    "# dataset_names = ['amazon', 'headlines', 'igg', 'twss']\n",
    "dataset_names = [\"amazon-headlines\", \"amazon-igg\", \"amazon-twss\", \"headlines-igg\", \"headlines-twss\", \"igg-twss\"]\n",
    "data_path = './Data/humor_datasets/'\n",
    "split_type = 'with_val_fixed_train'\n",
    "models_path = './Model/SavedModels/Bert-paired'\n",
    "base_model = 'bert'\n",
    "models_name = [glob.glob(f'{models_path}/{base_model}_on_{dataset}*')[0] for dataset in dataset_names]\n",
    "\n",
    "df = pd.read_excel(output_path + 'humor_results_template.xlsx')\n",
    "df.fillna(method='ffill', axis=0, inplace=True)\n",
    "df.set_index(['performance', 'model', 'trained on', 'seed'], inplace=True)\n",
    "\n",
    "for model_name in models_name:\n",
    "    # base_model, dataset_name, seed = get_run_details(model_name)\n",
    "    dataset_name, seed = get_run_details(model_name)\n",
    "    pred_path = model_name + '/predictions/'\n",
    "    accuracies = {}\n",
    "    recall = {}\n",
    "    precision = {}\n",
    "    predict_dataset_names = ['amazon', 'headlines', 'igg', 'twss']\n",
    "    for dataset in predict_dataset_names:\n",
    "        pred_labels_path = pred_path + f'{dataset}_preds.csv'\n",
    "        test_labels_path = data_path + f'{dataset}/{split_type}/test.csv'\n",
    "        if not (exists(pred_labels_path) and exists(test_labels_path)):\n",
    "            print('didnt find preds/test path')\n",
    "            continue\n",
    "\n",
    "        _preds = pd.read_csv(pred_labels_path)\n",
    "        _test = pd.read_csv(test_labels_path)\n",
    "        _test = _test.iloc[:len(_preds)]\n",
    "        if (len(_preds[_preds.label == -1]) > 0):\n",
    "            illegal_indices = _preds[_preds.label == -1].index\n",
    "            print(f'there are {len(illegal_indices)} illegal indices in {dataset_name} predictions on {dataset}')\n",
    "            _preds = _preds.drop(labels=illegal_indices, axis=0)\n",
    "            _test = _test.drop(labels=illegal_indices, axis=0)\n",
    "        accuracies[dataset] = float(\"%.4f\" % accuracy_score(_test.label, _preds.label))\n",
    "        recall[dataset] = float(\"%.4f\" % recall_score(_test.label, _preds.label))\n",
    "        precision[dataset] = float(\"%.4f\" % precision_score(_test.label, _preds.label))\n",
    "\n",
    "    print(f'performance for {model_name}')\n",
    "    print(f'accuracies = {accuracies}')\n",
    "    print(f'recall = {recall}')\n",
    "    print(f'precision = {precision}')\n",
    "\n",
    "    df.loc[('accuracy', base_model, dataset_name, seed)] = accuracies\n",
    "    df.loc[('recall', base_model, dataset_name, seed)] = recall\n",
    "    df.loc[('precision', base_model, dataset_name, seed)] = precision\n",
    "\n",
    "# save performance to output file\n",
    "i = 0\n",
    "while os.path.exists(output_path + f'humor_results_{i}.xlsx'):\n",
    "    i += 1\n",
    "\n",
    "df.to_excel(output_path + f'humor_results_{i}.xlsx')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# compute T5 models mean & std accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazon: 0.8551 +- 0.001\n",
      "headlines: 0.5816 +- 0.001\n",
      "igg: 0.9370 +- 0.002\n",
      "twss: 0.5555 +- 0.141\n"
     ]
    }
   ],
   "source": [
    "acc_igg = [0.9347826086956522, 0.9391304347826087, 0.9376811594202898, 0.936231884057971]\n",
    "acc_amazon = [0.8557142857142858, 0.8542857142857143, 0.8551428571428571, 0.8554285714285714]\n",
    "acc_headlines = [0.5831428571428572, 0.5805714285714285, 0.5822857142857143, 0.5805714285714285]\n",
    "acc_twss = [0.45634920634920634, 0.4777636594663278, 0.4885786802030457, 0.799492385786802]\n",
    "accs = {'amazon': acc_amazon, 'headlines': acc_headlines, 'igg': acc_igg, 'twss': acc_twss}\n",
    "for k,v in accs.items():\n",
    "    print(f'{k}: {\"%.4f\" % np.mean(v)} +- {\"%.3f\" % np.std(v)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# compute Bert models mean & std accuracy\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazon: 0.8361 +- 0.004\n",
      "headlines: 0.5954 +- 0.011\n",
      "igg: 0.8998 +- 0.015\n",
      "twss: 0.9940 +- 0.002\n"
     ]
    }
   ],
   "source": [
    "acc_igg = [0.9094412331406551, 0.9113680154142582, 0.9036608863198459, 0.8747591522157996]\n",
    "acc_amazon = [0.8414285714285714, 0.8368571428571429, 0.8305714285714285, 0.8354285714285714]\n",
    "acc_headlines = [0.5834285714285714, 0.586, 0.6031428571428571, 0.6091428571428571]\n",
    "acc_twss = [0.9949238578680203, 0.9898477157360406, 0.9961928934010152, 0.9949238578680203]\n",
    "accs = {'amazon': acc_amazon, 'headlines': acc_headlines, 'igg': acc_igg, 'twss': acc_twss}\n",
    "for k,v in accs.items():\n",
    "    print(f'{k}: {\"%.4f\" % np.mean(v)} +- {\"%.3f\" % np.std(v)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# compute T5 models on pairs mean & std"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazon_healines: 0.8299 +- 0.038\n",
      "amazon_igg: 0.8386 +- 0.019\n",
      "amazon_twss: 0.8500 +- 0.004\n",
      "headlines_igg: 0.5812 +- 0.002\n",
      "headlines_twss: 0.9841 +- 0.002\n",
      "igg_twss: 0.9075 +- 0.003\n"
     ]
    }
   ],
   "source": [
    "amazon_headlines_on_amazon = [0.7637142857142857, 0.8462857142857143, 0.8562857142857143, 0.8534285714285714]\n",
    "amazon_igg_on_amazon = [0.8071428571428572, 0.842, 0.8505714285714285, 0.8548571428571429]\n",
    "amazon_twss_on_amazon = [0.8431428571428572, 0.8505714285714285, 0.8531428571428571, 0.8531428571428571]\n",
    "headlines_igg_on_headlines = [0.5791428571428572, 0.5842857142857143, 0.5828571428571429, 0.5785714285714286]\n",
    "headlines_twss_on_twss = [0.9822335025380711, 0.983502538071066, 0.983502538071066, 0.9873096446700508]\n",
    "igg_twss_on_igg = [0.905587668593449, 0.905587668593449, 0.905587668593449, 0.9132947976878613]\n",
    "accs = {'amazon_healines': amazon_headlines_on_amazon,\n",
    "        'amazon_igg': amazon_igg_on_amazon,\n",
    "        'amazon_twss': amazon_twss_on_amazon,\n",
    "        'headlines_igg': headlines_igg_on_headlines,\n",
    "        'headlines_twss': headlines_twss_on_twss,\n",
    "        'igg_twss': igg_twss_on_igg}\n",
    "\n",
    "for k,v in accs.items():\n",
    "    print(f'{k}: {\"%.4f\" % np.mean(v)} +- {\"%.3f\" % np.std(v)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# compute Bert models on pairs mean & std"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazon_healines: 0.8295 +- 0.003\n",
      "amazon_igg: 0.8259 +- 0.006\n",
      "amazon_twss: 0.8068 +- 0.006\n",
      "headlines_igg: 0.8786 +- 0.005\n",
      "headlines_twss: 0.9854 +- 0.003\n",
      "igg_twss: 0.8420 +- 0.026\n"
     ]
    }
   ],
   "source": [
    "amazon_headlines_on_amazon = [0.8328571428571429, 0.83, 0.8294285714285714, 0.8257142857142857]\n",
    "amazon_igg_on_amazon = [0.8345714285714285, 0.8274285714285714, 0.8214285714285714, 0.8202857142857143]\n",
    "amazon_twss_on_amazon = [0.8105714285714286, 0.812, 0.7977142857142857, 0.8068571428571428]\n",
    "headlines_igg_on_igg = [0.8728323699421965, 0.8766859344894027, 0.8786127167630058, 0.8863198458574181]\n",
    "headlines_twss_on_twss = [0.9796954314720813, 0.9873096446700508, 0.9885786802030457, 0.9860406091370558]\n",
    "igg_twss_on_igg = [0.861271676300578, 0.8535645472061657, 0.7976878612716763, 0.8554913294797688]\n",
    "accs = {'amazon_healines': amazon_headlines_on_amazon,\n",
    "        'amazon_igg': amazon_igg_on_amazon,\n",
    "        'amazon_twss': amazon_twss_on_amazon,\n",
    "        'headlines_igg': headlines_igg_on_igg,\n",
    "        'headlines_twss': headlines_twss_on_twss,\n",
    "        'igg_twss': igg_twss_on_igg}\n",
    "\n",
    "for k,v in accs.items():\n",
    "    print(f'{k}: {\"%.4f\" % np.mean(v)} +- {\"%.3f\" % np.std(v)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# check headlines dataset meanGrade"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "processed_headlines_path = './Data/humor_datasets/headlines/with_val_fixed_train/{split}.csv'\n",
    "processed_train_df = pd.read_csv(processed_headlines_path.format(split='train'))\n",
    "processed_test_df = pd.read_csv(processed_headlines_path.format(split='test'))\n",
    "processed_val_df = pd.read_csv(processed_headlines_path.format(split='val'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "original_headlines_path = './Data/original_datasets/headlines/{split}.csv'\n",
    "original_train_df = pd.read_csv(original_headlines_path.format(split='train'))\n",
    "original_test_df = pd.read_csv(original_headlines_path.format(split='test'))\n",
    "original_all = original_train_df.append(original_test_df, ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def add_column_data(column_name):\n",
    "    def add_col_to_row(row):\n",
    "        origin_row = original_all[original_all['id'] == row['id']].squeeze()\n",
    "        return origin_row[column_name]\n",
    "    return add_col_to_row"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "cols = ['meanGrade', 'original', 'edit']\n",
    "for col in cols:\n",
    "    processed_train_df[col] = processed_train_df.apply(add_column_data(col), axis=1)\n",
    "    processed_test_df[col] = processed_test_df.apply(add_column_data(col), axis=1)\n",
    "    processed_val_df[col] = processed_val_df.apply(add_column_data(col), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "max_val_size = 3500\n",
    "processed_test_df = processed_test_df.iloc[:max_val_size]\n",
    "processed_val_df = processed_val_df.iloc[:max_val_size]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Grade stats:\n",
      "-- train --\n",
      "mean = 0.9420454545454544, std = 0.5772500621369475\n",
      "-- test --\n",
      "mean = 0.9382, std = 0.5886325917698874\n",
      "-- val --\n",
      "mean = 0.9175238095238093, std = 0.5766939173305733\n"
     ]
    }
   ],
   "source": [
    "print('Mean Grade stats:')\n",
    "print(f'-- train --')\n",
    "print(f'mean = {processed_train_df.meanGrade.mean()}, std = {processed_train_df.meanGrade.std()}')\n",
    "print(f'-- test --')\n",
    "print(f'mean = {processed_test_df.meanGrade.mean()}, std = {processed_test_df.meanGrade.std()}')\n",
    "print(f'-- val --')\n",
    "print(f'mean = {processed_val_df.meanGrade.mean()}, std = {processed_val_df.meanGrade.std()}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "sample_size = 100\n",
    "sample_train = processed_train_df.iloc[:sample_size]\n",
    "sample_test = processed_test_df.iloc[:sample_size]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "output_path = './Data/output/headlines_data_samples/'\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "sample_train.to_csv(output_path + 'train.csv', index=False)\n",
    "sample_test.to_csv(output_path + 'test.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## check headlines dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "headlines_path = './Data/humor_datasets/headlines/{sanity}with_val_fixed_train'\n",
    "real_train = pd.read_csv(headlines_path.format(sanity='') + '/train.csv')\n",
    "real_test = pd.read_csv(headlines_path.format(sanity='') + '/test.csv')\n",
    "sanity_train = pd.read_csv(headlines_path.format(sanity='sanity-check/') + '/train.csv')\n",
    "sanity_test = pd.read_csv(headlines_path.format(sanity='sanity-check/') + '/test.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "original_headlines_path = './Data/original_datasets/headlines/{split}.csv'\n",
    "original_train = pd.read_csv(original_headlines_path.format(split='train'))\n",
    "original_test = pd.read_csv(original_headlines_path.format(split='test'))\n",
    "all_data = original_test.append(original_train, ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def edit_headline(row):\n",
    "    headline = row['original']\n",
    "    edit_word = row['edit']\n",
    "    res = headline[:headline.index('<')] + edit_word + headline[headline.index('>') + 1:]\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "all_data['edited_sentence'] = all_data.apply(edit_headline, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def add_mean_grade(row):\n",
    "    origin_row = all_data[all_data['id'] == row['id']].squeeze()\n",
    "    return origin_row['meanGrade']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "real_train['meanGrade'] = real_train.apply(add_mean_grade, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# T5 on all headlines acccuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines accuracy: mean = 0.6258, std = 0.0063\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "headlines_accuracies = [0.6127912741695587, 0.6326227069905801, 0.6351016360932077, 0.6271690629647992,\n",
    "0.6256817055032227, 0.6256817055032227, 0.624194348041646, 0.623202776400595]\n",
    "print(f'headlines accuracy: mean = {\"%.4f\" % np.mean(headlines_accuracies)}, std = {\"%.4f\" % np.std(headlines_accuracies)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Trying kfold"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data_path = './Data/humor_datasets/headlines/kfold_cv/'\n",
    "data = pd.read_csv(data_path + 'data.csv')\n",
    "os.makedirs(data_path + 'folds/', exist_ok=True)\n",
    "kfold = StratifiedKFold(4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size = 9295, test size = 3099\n",
      "label 1 % = 49.994620763851536\n",
      "train size = 9295, test size = 3099\n",
      "label 1 % = 50.005379236148464\n",
      "train size = 9296, test size = 3098\n",
      "label 1 % = 50.0\n",
      "train size = 9296, test size = 3098\n",
      "label 1 % = 50.0\n"
     ]
    }
   ],
   "source": [
    "for i, indices in enumerate(kfold.split(data, data['label'])):\n",
    "    train = indices[0]\n",
    "    test = indices[1]\n",
    "    # print('train: %s, test: %s' % (train, test))\n",
    "    print(f'train size = {len(train)}, test size = {len(test)}')\n",
    "    data_train = data.iloc[train]\n",
    "    print(f'label 1 % = {100 * len(data_train[data_train.label == 1]) / len(data_train)}')\n",
    "    data_test = data.iloc[test]\n",
    "    data_test, data_val = train_test_split(data_test, test_size=0.5, shuffle=True, random_state=0)\n",
    "    output_path = data_path + f'folds/fold_{i}/with_val/'\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    data_train.to_csv(output_path + 'train.csv', index=False)\n",
    "    data_test.to_csv(output_path + 'test.csv', index=False)\n",
    "    data_val.to_csv(output_path + 'val.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size = 2560, test size = 854\n",
      "label 1 % = 49.609375\n",
      "train size = 2560, test size = 854\n",
      "label 1 % = 50.1953125\n",
      "train size = 2561, test size = 853\n",
      "label 1 % = 51.34713002733307\n",
      "train size = 2561, test size = 853\n",
      "label 1 % = 50.488090589613435\n"
     ]
    }
   ],
   "source": [
    "datasets = ['amazon', 'headlines', 'igg', 'twss']\n",
    "output_path = './Data/humor_datasets/{dataset}/kfold_cv/'\n",
    "input_path = './Data/humor_datasets/{dataset}/data.csv'\n",
    "kfold = StratifiedKFold(n_splits=4)\n",
    "\n",
    "# compute fixed train size by igg train size\n",
    "igg_df = pd.read_csv(output_path.format(dataset='igg') + 'balanced_data.csv')\n",
    "splits = kfold.split(igg_df, igg_df['label'])\n",
    "for train, test in splits:\n",
    "    # print('train: %s, test: %s' % (train, test))\n",
    "    print(f'train size = {len(train)}, test size = {len(test)}')\n",
    "    data_train = data.iloc[train]\n",
    "    print(f'label 1 % = {100 * len(data_train[data_train.label == 1]) / len(data_train)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are common rows.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrames\n",
    "df1 = pd.DataFrame({'A': [1, 2, 3, 4],\n",
    "                    'B': ['X', 'Y', 'Z', 'W']})\n",
    "\n",
    "df2 = pd.DataFrame({'A': [3, 2, 5, 6],\n",
    "                    'B': ['Z', 'Y', 'P', 'Q']})\n",
    "\n",
    "# Check for common rows\n",
    "common_rows = df1[df1.isin(df2.to_dict(orient='list')).all(axis=1)]\n",
    "\n",
    "# Check if there are common rows\n",
    "if not common_rows.empty:\n",
    "    print(\"There are common rows.\")\n",
    "else:\n",
    "    print(\"There are no common rows.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}